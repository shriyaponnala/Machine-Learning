{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":64684,"databundleVersionId":7098519,"sourceType":"competition"},{"sourceId":7205441,"sourceType":"datasetVersion","datasetId":4168414}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\nimport numpy as np\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate,Dense,Flatten,Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import load_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-15T02:27:43.776713Z","iopub.execute_input":"2023-12-15T02:27:43.777006Z","iopub.status.idle":"2023-12-15T02:28:01.739424Z","shell.execute_reply.started":"2023-12-15T02:27:43.776980Z","shell.execute_reply":"2023-12-15T02:28:01.738641Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"#Loading the Image and mask information paths\nim_path = \"/kaggle/input/cs770-final-project-skin-lesion-segmentation/Project_Data/Train/images\"\nmask_path = \"/kaggle/input/cs770-final-project-skin-lesion-segmentation/Project_Data/Train/masks\"\n\nim_list = []\nfor filename in os.listdir(im_path):\n    if filename.endswith((\".jpg\")):  # Add more image extensions if needed\n        # Construct the full path to the image\n        im_list.append(os.path.join(im_path, filename))\nim_list.sort()     \n\nmask_list = []\nfor filename in os.listdir(mask_path):\n    if filename.endswith((\".png\")):  # Add more image extensions if needed\n        # Construct the full path to the image\n        mask_list.append(os.path.join(mask_path, filename))\nmask_list.sort()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:30:33.990792Z","iopub.execute_input":"2023-12-15T02:30:33.991450Z","iopub.status.idle":"2023-12-15T02:30:34.531052Z","shell.execute_reply.started":"2023-12-15T02:30:33.991416Z","shell.execute_reply":"2023-12-15T02:30:34.530206Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Create a CNN model equivalent to the VGG-16.\nmodel1 = Sequential()\n# Block 1\nmodel1.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(112,112,3)))\nmodel1.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n# Block 2\nmodel1.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel1.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n# Block 3\nmodel1.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel1.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel1.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n#Middle\nmodel1.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel1.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n\n# Flatten\nmodel1.add(Flatten())\n\n# Fully connected layers\nmodel1.add(Dense(128, activation='relu'))\nmodel1.add(Dropout(0.2))\nmodel1.add(Dense(64, activation='relu'))\nmodel1.add(Dropout(0.2))\nmodel1.add(Dense(32, activation='relu'))\nmodel1.add(Dense(7, activation='softmax'))\n# Compile the model\nmodel1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Print the model summary\nmodel1.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:30:42.040783Z","iopub.execute_input":"2023-12-15T02:30:42.041493Z","iopub.status.idle":"2023-12-15T02:30:48.031845Z","shell.execute_reply.started":"2023-12-15T02:30:42.041452Z","shell.execute_reply":"2023-12-15T02:30:48.030888Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 112, 112, 32)      896       \n                                                                 \n conv2d_1 (Conv2D)           (None, 112, 112, 32)      9248      \n                                                                 \n max_pooling2d (MaxPooling2  (None, 56, 56, 32)        0         \n D)                                                              \n                                                                 \n conv2d_2 (Conv2D)           (None, 56, 56, 64)        18496     \n                                                                 \n conv2d_3 (Conv2D)           (None, 56, 56, 64)        36928     \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 28, 28, 64)        0         \n g2D)                                                            \n                                                                 \n conv2d_4 (Conv2D)           (None, 28, 28, 128)       73856     \n                                                                 \n conv2d_5 (Conv2D)           (None, 28, 28, 128)       147584    \n                                                                 \n conv2d_6 (Conv2D)           (None, 28, 28, 128)       147584    \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n g2D)                                                            \n                                                                 \n conv2d_7 (Conv2D)           (None, 14, 14, 32)        36896     \n                                                                 \n conv2d_8 (Conv2D)           (None, 14, 14, 32)        9248      \n                                                                 \n flatten (Flatten)           (None, 6272)              0         \n                                                                 \n dense (Dense)               (None, 128)               802944    \n                                                                 \n dropout (Dropout)           (None, 128)               0         \n                                                                 \n dense_1 (Dense)             (None, 64)                8256      \n                                                                 \n dropout_1 (Dropout)         (None, 64)                0         \n                                                                 \n dense_2 (Dense)             (None, 32)                2080      \n                                                                 \n dense_3 (Dense)             (None, 7)                 231       \n                                                                 \n=================================================================\nTotal params: 1294247 (4.94 MB)\nTrainable params: 1294247 (4.94 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#Image pixel data loading as we resize it to (112,112,3)\nim_info = []\nfor j in range(len(im_list)):\n    im_info.append(cv2.resize(cv2.imread(im_list[j]), (112, 112)))\nim_info = np.array(im_info)/255\n\nlabel_info = pd.read_csv(\"/kaggle/input/cs770-final-project-skin-lesion-segmentation/Project_Data/Train/GroundTruth.csv\")\nlabel_info = label_info.iloc[:,1:].values\n\nfrom sklearn.utils import shuffle\nim_info,label_info = shuffle(im_info,label_info)\nim_test_info = im_info[8000:]\nlabel_test_info = label_info[8000:]\nim_info = im_info[:8000]\nlabel_info = label_info[:8000]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:31:24.352926Z","iopub.execute_input":"2023-12-15T02:31:24.353305Z","iopub.status.idle":"2023-12-15T02:34:33.011192Z","shell.execute_reply.started":"2023-12-15T02:31:24.353276Z","shell.execute_reply":"2023-12-15T02:34:33.010119Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Model Training\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nmodel_checkpoint = ModelCheckpoint('/kaggle/working/main_model.h5', monitor='val_loss', save_best_only=True)\nhistory = model1.fit(im_info,label_info, epochs=100,batch_size=64, validation_data=(im_test_info,label_test_info),callbacks=[early_stopping,model_checkpoint])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:35:37.188837Z","iopub.execute_input":"2023-12-15T02:35:37.189239Z","iopub.status.idle":"2023-12-15T02:38:51.548191Z","shell.execute_reply.started":"2023-12-15T02:35:37.189209Z","shell.execute_reply":"2023-12-15T02:38:51.547135Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/100\n125/125 [==============================] - 28s 77ms/step - loss: 1.1860 - accuracy: 0.6352 - val_loss: 0.9737 - val_accuracy: 0.6779\nEpoch 2/100\n  2/125 [..............................] - ETA: 7s - loss: 0.9858 - accuracy: 0.6797","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"125/125 [==============================] - 8s 64ms/step - loss: 1.0109 - accuracy: 0.6671 - val_loss: 0.9205 - val_accuracy: 0.6779\nEpoch 3/100\n125/125 [==============================] - 8s 64ms/step - loss: 0.9585 - accuracy: 0.6671 - val_loss: 0.8881 - val_accuracy: 0.6779\nEpoch 4/100\n125/125 [==============================] - 8s 63ms/step - loss: 0.9312 - accuracy: 0.6700 - val_loss: 1.0272 - val_accuracy: 0.6868\nEpoch 5/100\n125/125 [==============================] - 8s 64ms/step - loss: 0.9154 - accuracy: 0.6711 - val_loss: 0.8784 - val_accuracy: 0.6948\nEpoch 6/100\n125/125 [==============================] - 8s 63ms/step - loss: 0.8987 - accuracy: 0.6776 - val_loss: 0.8793 - val_accuracy: 0.6933\nEpoch 7/100\n125/125 [==============================] - 8s 65ms/step - loss: 0.8759 - accuracy: 0.6855 - val_loss: 0.8417 - val_accuracy: 0.7012\nEpoch 8/100\n125/125 [==============================] - 8s 65ms/step - loss: 0.8532 - accuracy: 0.6844 - val_loss: 0.7989 - val_accuracy: 0.7067\nEpoch 9/100\n125/125 [==============================] - 8s 65ms/step - loss: 0.8371 - accuracy: 0.6986 - val_loss: 0.7925 - val_accuracy: 0.7171\nEpoch 10/100\n125/125 [==============================] - 8s 65ms/step - loss: 0.8134 - accuracy: 0.7092 - val_loss: 0.7858 - val_accuracy: 0.7206\nEpoch 11/100\n125/125 [==============================] - 8s 65ms/step - loss: 0.7950 - accuracy: 0.7086 - val_loss: 0.7778 - val_accuracy: 0.7270\nEpoch 12/100\n125/125 [==============================] - 8s 65ms/step - loss: 0.7766 - accuracy: 0.7130 - val_loss: 0.7782 - val_accuracy: 0.7241\nEpoch 13/100\n125/125 [==============================] - 8s 65ms/step - loss: 0.7914 - accuracy: 0.7178 - val_loss: 0.8086 - val_accuracy: 0.7141\nEpoch 14/100\n125/125 [==============================] - 8s 66ms/step - loss: 0.7417 - accuracy: 0.7333 - val_loss: 0.7692 - val_accuracy: 0.7295\nEpoch 15/100\n125/125 [==============================] - 8s 65ms/step - loss: 0.6906 - accuracy: 0.7489 - val_loss: 0.7996 - val_accuracy: 0.7236\nEpoch 16/100\n125/125 [==============================] - 8s 66ms/step - loss: 0.6392 - accuracy: 0.7664 - val_loss: 0.7548 - val_accuracy: 0.7385\nEpoch 17/100\n125/125 [==============================] - 8s 66ms/step - loss: 0.5962 - accuracy: 0.7815 - val_loss: 0.8296 - val_accuracy: 0.7196\nEpoch 18/100\n125/125 [==============================] - 8s 65ms/step - loss: 0.5376 - accuracy: 0.8069 - val_loss: 0.8685 - val_accuracy: 0.7132\nEpoch 19/100\n125/125 [==============================] - 8s 66ms/step - loss: 0.4986 - accuracy: 0.8185 - val_loss: 0.9603 - val_accuracy: 0.7290\nEpoch 20/100\n125/125 [==============================] - 8s 66ms/step - loss: 0.4329 - accuracy: 0.8425 - val_loss: 0.9440 - val_accuracy: 0.7201\nEpoch 21/100\n125/125 [==============================] - 8s 66ms/step - loss: 0.3999 - accuracy: 0.8565 - val_loss: 0.9977 - val_accuracy: 0.7241\n","output_type":"stream"}]},{"cell_type":"code","source":"#Model downloading\nmodel1.save('/kaggle/working/main_model.h5')\nimport os \nos.chdir(r'/kaggle/working') \nfrom IPython.display import FileLink \nFileLink(r'main_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:39:47.646524Z","iopub.execute_input":"2023-12-15T02:39:47.649788Z","iopub.status.idle":"2023-12-15T02:39:47.753204Z","shell.execute_reply.started":"2023-12-15T02:39:47.649751Z","shell.execute_reply":"2023-12-15T02:39:47.752163Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/main_model.h5","text/html":"<a href='main_model.h5' target='_blank'>main_model.h5</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"#Loading the test data\nim_test_path = \"/kaggle/input/cs770-final-project-skin-lesion-segmentation/Project_Data/Test/ISIC2018_Task3_Test_Input/\"\nlabel_test_info = pd.read_csv(\"/kaggle/input/cs770-final-project-skin-lesion-segmentation/Project_Data/Test/ISIC2018_Task3_Test_GroundTruth/ISIC2018_Task3_Test_GroundTruth.csv\")\nlabel_test_info = label_test_info.iloc[:,1:]\n\nim_test_list = []\nfor filename in os.listdir(im_test_path):\n    if filename.endswith((\".jpg\")):  # Add more image extensions if needed\n        # Construct the full path to the image\n        im_test_list.append(os.path.join(im_test_path, filename))\nim_test_list.sort()     ","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:41:24.635819Z","iopub.execute_input":"2023-12-15T02:41:24.636201Z","iopub.status.idle":"2023-12-15T02:41:24.653364Z","shell.execute_reply.started":"2023-12-15T02:41:24.636169Z","shell.execute_reply":"2023-12-15T02:41:24.652463Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Resizing the test data\nim_test_info = []\nfor j in range(len(im_test_list)):\n    im_test_info.append(cv2.resize(cv2.imread(im_test_list[j]), (112, 112)))\nim_test_info = np.array(im_test_info)/255","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:41:41.655801Z","iopub.execute_input":"2023-12-15T02:41:41.656648Z","iopub.status.idle":"2023-12-15T02:42:10.385987Z","shell.execute_reply.started":"2023-12-15T02:41:41.656614Z","shell.execute_reply":"2023-12-15T02:42:10.385142Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Using test data to run the model\nim_class_prediction = model1.predict(im_test_info)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:42:20.142512Z","iopub.execute_input":"2023-12-15T02:42:20.143125Z","iopub.status.idle":"2023-12-15T02:42:21.949322Z","shell.execute_reply.started":"2023-12-15T02:42:20.143091Z","shell.execute_reply":"2023-12-15T02:42:21.948473Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"48/48 [==============================] - 1s 13ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nim_class_prediction = [to_categorical(np.argmax(i), num_classes=7) for i in im_class_prediction]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:44:35.604174Z","iopub.execute_input":"2023-12-15T02:44:35.604572Z","iopub.status.idle":"2023-12-15T02:44:35.647591Z","shell.execute_reply.started":"2023-12-15T02:44:35.604543Z","shell.execute_reply":"2023-12-15T02:44:35.646856Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"im_class_prediction=np.array(im_class_prediction)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:46:41.035809Z","iopub.execute_input":"2023-12-15T02:46:41.036166Z","iopub.status.idle":"2023-12-15T02:46:41.042343Z","shell.execute_reply.started":"2023-12-15T02:46:41.036140Z","shell.execute_reply":"2023-12-15T02:46:41.041407Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n\ndef normalized_multi_class_accuracy(y_true_info, y_prediction_info):\n    true_pos = K.sum(K.round(K.clip(y_true_info * y_prediction_info, 0, 1)), axis=0)\n    true_neg = K.sum(K.round(K.clip((1 - y_true_info) * (1 - y_prediction_info), 0, 1)), axis=0)\n    total_samples = K.sum(K.round(K.clip(y_true_info + (1 - y_true_info), 0, 1)), axis=0)\n\n    class_acc = (true_pos + true_neg) / (total_samples + K.epsilon())\n    normalized_acc = K.mean(class_acc)\n\n    return normalized_acc","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:42:40.219758Z","iopub.execute_input":"2023-12-15T02:42:40.220638Z","iopub.status.idle":"2023-12-15T02:42:40.227338Z","shell.execute_reply.started":"2023-12-15T02:42:40.220601Z","shell.execute_reply":"2023-12-15T02:42:40.226310Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Normalized multiclass accuracy for classification model\nnormalized_multi_class_accuracy(label_test_info,im_class_prediction).numpy()*100","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:47:35.206176Z","iopub.execute_input":"2023-12-15T02:47:35.206848Z","iopub.status.idle":"2023-12-15T02:47:35.218873Z","shell.execute_reply.started":"2023-12-15T02:47:35.206815Z","shell.execute_reply":"2023-12-15T02:47:35.217821Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"90.0415721784742"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Model training for image segmentation**","metadata":{}},{"cell_type":"code","source":"#Developing an unet model for image segmentation.\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n\ndef seg_unet_model(input_shape=(112, 112, 3), num_classes=7):\n    inputs = Input(input_shape)\n\n    # Encoder\n    conv1 = Conv2D(32, 3, activation='relu', padding='same', trainable=False)(inputs)\n    conv1 = Conv2D(32, 3, activation='relu', padding='same', trainable=False)(conv1)\n    pooling1 = MaxPooling2D(pool_size=(2, 2), trainable=False)(conv1)\n\n    conv2 = Conv2D(64, 3, activation='relu', padding='same', trainable=False)(pooling1)\n    conv2 = Conv2D(64, 3, activation='relu', padding='same', trainable=False)(conv2)\n    pooling2 = MaxPooling2D(pool_size=(2, 2), trainable=False)(conv2)\n\n    conv3 = Conv2D(128, 3, activation='relu', padding='same', trainable=False)(pooling2)\n    conv3 = Conv2D(128, 3, activation='relu', padding='same', trainable=False)(conv3)\n    conv3 = Conv2D(128, 3, activation='relu', padding='same', trainable=False)(conv3)\n    pooling3 = MaxPooling2D(pool_size=(2, 2), trainable=False)(conv3)\n\n    # Bottom layer\n    conv4 = Conv2D(32, 3, activation='relu', padding='same', trainable=False)(pooling3)\n    conv4 = Conv2D(32, 3, activation='relu', padding='same', trainable=False)(conv4)\n\n    # Decoder\n    up5 = UpSampling2D(size=(2, 2))(conv4)\n    concat5 = concatenate([conv3,up5], axis=-1)\n    conv5 = Conv2D(128, 3, activation='relu', padding='same')(concat5)\n    conv5 = Conv2D(128, 3, activation='relu', padding='same')(conv5)\n    conv5 = Conv2D(128, 3, activation='relu', padding='same')(conv5)\n\n    up6 = UpSampling2D(size=(2, 2))(conv5)\n    concat6 = concatenate([conv2,up6], axis=-1)\n    conv6 = Conv2D(64, 3, activation='relu', padding='same')(concat6)\n    conv6 = Conv2D(64, 3, activation='relu', padding='same')(conv6)\n\n    up7 = UpSampling2D(size=(2, 2))(conv6)\n    concat7 = concatenate([conv1,up7], axis=-1)\n    conv7 = Conv2D(32, 3, activation='relu', padding='same')(concat7)\n    conv7 = Conv2D(32, 3, activation='relu', padding='same')(conv7)\n    \n    # Output layer\n    outputs = Conv2D(3, 1, activation='sigmoid')(conv7)\n\n    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n\n    return model\n\n# Create U-Net model\nsegmentation_model = seg_unet_model()\n\n# Print the model summary\nsegmentation_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:50:58.640682Z","iopub.execute_input":"2023-12-15T02:50:58.641075Z","iopub.status.idle":"2023-12-15T02:50:58.909183Z","shell.execute_reply.started":"2023-12-15T02:50:58.641046Z","shell.execute_reply":"2023-12-15T02:50:58.907523Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_2 (InputLayer)        [(None, 112, 112, 3)]        0         []                            \n                                                                                                  \n conv2d_26 (Conv2D)          (None, 112, 112, 32)         896       ['input_2[0][0]']             \n                                                                                                  \n conv2d_27 (Conv2D)          (None, 112, 112, 32)         9248      ['conv2d_26[0][0]']           \n                                                                                                  \n max_pooling2d_6 (MaxPoolin  (None, 56, 56, 32)           0         ['conv2d_27[0][0]']           \n g2D)                                                                                             \n                                                                                                  \n conv2d_28 (Conv2D)          (None, 56, 56, 64)           18496     ['max_pooling2d_6[0][0]']     \n                                                                                                  \n conv2d_29 (Conv2D)          (None, 56, 56, 64)           36928     ['conv2d_28[0][0]']           \n                                                                                                  \n max_pooling2d_7 (MaxPoolin  (None, 28, 28, 64)           0         ['conv2d_29[0][0]']           \n g2D)                                                                                             \n                                                                                                  \n conv2d_30 (Conv2D)          (None, 28, 28, 128)          73856     ['max_pooling2d_7[0][0]']     \n                                                                                                  \n conv2d_31 (Conv2D)          (None, 28, 28, 128)          147584    ['conv2d_30[0][0]']           \n                                                                                                  \n conv2d_32 (Conv2D)          (None, 28, 28, 128)          147584    ['conv2d_31[0][0]']           \n                                                                                                  \n max_pooling2d_8 (MaxPoolin  (None, 14, 14, 128)          0         ['conv2d_32[0][0]']           \n g2D)                                                                                             \n                                                                                                  \n conv2d_33 (Conv2D)          (None, 14, 14, 32)           36896     ['max_pooling2d_8[0][0]']     \n                                                                                                  \n conv2d_34 (Conv2D)          (None, 14, 14, 32)           9248      ['conv2d_33[0][0]']           \n                                                                                                  \n up_sampling2d_3 (UpSamplin  (None, 28, 28, 32)           0         ['conv2d_34[0][0]']           \n g2D)                                                                                             \n                                                                                                  \n concatenate_3 (Concatenate  (None, 28, 28, 160)          0         ['conv2d_32[0][0]',           \n )                                                                   'up_sampling2d_3[0][0]']     \n                                                                                                  \n conv2d_35 (Conv2D)          (None, 28, 28, 128)          184448    ['concatenate_3[0][0]']       \n                                                                                                  \n conv2d_36 (Conv2D)          (None, 28, 28, 128)          147584    ['conv2d_35[0][0]']           \n                                                                                                  \n conv2d_37 (Conv2D)          (None, 28, 28, 128)          147584    ['conv2d_36[0][0]']           \n                                                                                                  \n up_sampling2d_4 (UpSamplin  (None, 56, 56, 128)          0         ['conv2d_37[0][0]']           \n g2D)                                                                                             \n                                                                                                  \n concatenate_4 (Concatenate  (None, 56, 56, 192)          0         ['conv2d_29[0][0]',           \n )                                                                   'up_sampling2d_4[0][0]']     \n                                                                                                  \n conv2d_38 (Conv2D)          (None, 56, 56, 64)           110656    ['concatenate_4[0][0]']       \n                                                                                                  \n conv2d_39 (Conv2D)          (None, 56, 56, 64)           36928     ['conv2d_38[0][0]']           \n                                                                                                  \n up_sampling2d_5 (UpSamplin  (None, 112, 112, 64)         0         ['conv2d_39[0][0]']           \n g2D)                                                                                             \n                                                                                                  \n concatenate_5 (Concatenate  (None, 112, 112, 96)         0         ['conv2d_27[0][0]',           \n )                                                                   'up_sampling2d_5[0][0]']     \n                                                                                                  \n conv2d_40 (Conv2D)          (None, 112, 112, 32)         27680     ['concatenate_5[0][0]']       \n                                                                                                  \n conv2d_41 (Conv2D)          (None, 112, 112, 32)         9248      ['conv2d_40[0][0]']           \n                                                                                                  \n conv2d_42 (Conv2D)          (None, 112, 112, 3)          99        ['conv2d_41[0][0]']           \n                                                                                                  \n==================================================================================================\nTotal params: 1144963 (4.37 MB)\nTrainable params: 664227 (2.53 MB)\nNon-trainable params: 480736 (1.83 MB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#Loading the previous classification model\nmain_model=load_model(\"/kaggle/input/main-model/main_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:53:31.887490Z","iopub.execute_input":"2023-12-15T02:53:31.887879Z","iopub.status.idle":"2023-12-15T02:53:32.455029Z","shell.execute_reply.started":"2023-12-15T02:53:31.887851Z","shell.execute_reply":"2023-12-15T02:53:32.454162Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#Transfer Learning involves fixing the weights of non-trainable layers.\nsegmentation_model.layers[1].set_weights(main_model.layers[0].get_weights())\nsegmentation_model.layers[2].set_weights(main_model.layers[1].get_weights())\nsegmentation_model.layers[4].set_weights(main_model.layers[3].get_weights())\nsegmentation_model.layers[5].set_weights(main_model.layers[4].get_weights())\nsegmentation_model.layers[7].set_weights(main_model.layers[6].get_weights())\nsegmentation_model.layers[8].set_weights(main_model.layers[7].get_weights())\nsegmentation_model.layers[9].set_weights(main_model.layers[8].get_weights())\nsegmentation_model.layers[11].set_weights(main_model.layers[10].get_weights())\nsegmentation_model.layers[12].set_weights(main_model.layers[11].get_weights())","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:53:36.655391Z","iopub.execute_input":"2023-12-15T02:53:36.656171Z","iopub.status.idle":"2023-12-15T02:53:36.681674Z","shell.execute_reply.started":"2023-12-15T02:53:36.656137Z","shell.execute_reply":"2023-12-15T02:53:36.680868Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"#Loading and resizing the image data and mask data\nim_info = []\nmask_info = []\nfor j in range(len(im_list)):\n    im_info.append(cv2.resize(cv2.imread(im_list[j]), (112, 112)))\n    mask_info.append(cv2.resize(cv2.imread(mask_list[j]), (112, 112)))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:54:08.140997Z","iopub.execute_input":"2023-12-15T02:54:08.141927Z","iopub.status.idle":"2023-12-15T02:57:11.980722Z","shell.execute_reply.started":"2023-12-15T02:54:08.141893Z","shell.execute_reply":"2023-12-15T02:57:11.979676Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"im_info = np.array(im_info)/255\nmask_info = np.array(mask_info)/255\n\nfrom sklearn.utils import shuffle\nim_info,mask_info = shuffle(im_info,mask_info)\nim_test_info = im_info[8000:]\nmask_test = mask_info[8000:]\nim_info = im_info[:8000]\nmask_info = mask_info[:8000]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:57:21.741085Z","iopub.execute_input":"2023-12-15T02:57:21.741485Z","iopub.status.idle":"2023-12-15T02:57:25.723155Z","shell.execute_reply.started":"2023-12-15T02:57:21.741447Z","shell.execute_reply":"2023-12-15T02:57:25.722356Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#Model training\nsegmentation_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:57:35.723895Z","iopub.execute_input":"2023-12-15T02:57:35.724299Z","iopub.status.idle":"2023-12-15T02:57:35.737470Z","shell.execute_reply.started":"2023-12-15T02:57:35.724271Z","shell.execute_reply":"2023-12-15T02:57:35.736666Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nhistory = segmentation_model.fit(im_info,mask_info, epochs=100,batch_size=64, validation_data=(im_test_info,mask_test),callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:57:45.808168Z","iopub.execute_input":"2023-12-15T02:57:45.808819Z","iopub.status.idle":"2023-12-15T03:03:52.873170Z","shell.execute_reply.started":"2023-12-15T02:57:45.808789Z","shell.execute_reply":"2023-12-15T03:03:52.872167Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/100\n125/125 [==============================] - 28s 179ms/step - loss: 0.2886 - accuracy: 0.3316 - val_loss: 0.2149 - val_accuracy: 0.1718\nEpoch 2/100\n125/125 [==============================] - 20s 159ms/step - loss: 0.1996 - accuracy: 0.2537 - val_loss: 0.1822 - val_accuracy: 0.2668\nEpoch 3/100\n125/125 [==============================] - 20s 160ms/step - loss: 0.1763 - accuracy: 0.2740 - val_loss: 0.1898 - val_accuracy: 0.3661\nEpoch 4/100\n125/125 [==============================] - 20s 162ms/step - loss: 0.1668 - accuracy: 0.2835 - val_loss: 0.1613 - val_accuracy: 0.2372\nEpoch 5/100\n125/125 [==============================] - 20s 164ms/step - loss: 0.1585 - accuracy: 0.2918 - val_loss: 0.1601 - val_accuracy: 0.3540\nEpoch 6/100\n125/125 [==============================] - 21s 164ms/step - loss: 0.1577 - accuracy: 0.3327 - val_loss: 0.1612 - val_accuracy: 0.3417\nEpoch 7/100\n125/125 [==============================] - 21s 165ms/step - loss: 0.1514 - accuracy: 0.3496 - val_loss: 0.1613 - val_accuracy: 0.3643\nEpoch 8/100\n125/125 [==============================] - 21s 166ms/step - loss: 0.1471 - accuracy: 0.3404 - val_loss: 0.1676 - val_accuracy: 0.3465\nEpoch 9/100\n125/125 [==============================] - 21s 167ms/step - loss: 0.1460 - accuracy: 0.3202 - val_loss: 0.1529 - val_accuracy: 0.2991\nEpoch 10/100\n125/125 [==============================] - 21s 167ms/step - loss: 0.1424 - accuracy: 0.2772 - val_loss: 0.1505 - val_accuracy: 0.3004\nEpoch 11/100\n125/125 [==============================] - 21s 168ms/step - loss: 0.1386 - accuracy: 0.2759 - val_loss: 0.1505 - val_accuracy: 0.2745\nEpoch 12/100\n125/125 [==============================] - 21s 170ms/step - loss: 0.1356 - accuracy: 0.2419 - val_loss: 0.1445 - val_accuracy: 0.2135\nEpoch 13/100\n125/125 [==============================] - 21s 169ms/step - loss: 0.1337 - accuracy: 0.2307 - val_loss: 0.1460 - val_accuracy: 0.2238\nEpoch 14/100\n125/125 [==============================] - 21s 169ms/step - loss: 0.1323 - accuracy: 0.2388 - val_loss: 0.1524 - val_accuracy: 0.2081\nEpoch 15/100\n125/125 [==============================] - 21s 169ms/step - loss: 0.1300 - accuracy: 0.2371 - val_loss: 0.1492 - val_accuracy: 0.2593\nEpoch 16/100\n125/125 [==============================] - 21s 169ms/step - loss: 0.1278 - accuracy: 0.2352 - val_loss: 0.1459 - val_accuracy: 0.2093\nEpoch 17/100\n125/125 [==============================] - 21s 169ms/step - loss: 0.1252 - accuracy: 0.2287 - val_loss: 0.1507 - val_accuracy: 0.2526\n","output_type":"stream"}]},{"cell_type":"code","source":"#Observing test data paths\nim_test_path = \"/kaggle/input/cs770-final-project-skin-lesion-segmentation/Project_Data/Test/ISBI2016_ISIC_Part1_Test_Data/\"\nmask_test_path = \"/kaggle/input/cs770-final-project-skin-lesion-segmentation/Project_Data/Test/ISBI2016_ISIC_Part1_Test_GroundTruth\"\n\nim_test_list = []\nfor filename in os.listdir(im_test_path):\n    if filename.endswith((\".jpg\")):  # Add more image extensions if needed\n        # Construct the full path to the image\n        im_test_list.append(os.path.join(im_test_path, filename))\nim_test_list.sort()   \n\nmask_test_list = []\nfor filename in os.listdir(mask_test_path):\n    if filename.endswith((\".png\")):  # Add more image extensions if needed\n        # Construct the full path to the image\n        mask_test_list.append(os.path.join(mask_test_path, filename))\nmask_test_list.sort()   ","metadata":{"execution":{"iopub.status.busy":"2023-12-15T03:04:17.577678Z","iopub.execute_input":"2023-12-15T03:04:17.578160Z","iopub.status.idle":"2023-12-15T03:04:17.806679Z","shell.execute_reply.started":"2023-12-15T03:04:17.578125Z","shell.execute_reply":"2023-12-15T03:04:17.805977Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#Loading and resizing the test data \nim_test_info = []\nfor j in range(len(im_test_list)):\n    im_test_info.append(cv2.resize(cv2.imread(im_test_list[j]), (112, 112)))\nim_test_info = np.array(im_test_info)/255\n\nmask_test_info = []\nfor j in range(len(mask_test_list)):\n    mask_test_info.append(cv2.resize(cv2.imread(mask_test_list[j]), (112, 112)))\nmask_test_info = np.array(mask_test_info)/255","metadata":{"execution":{"iopub.status.busy":"2023-12-15T03:04:23.745692Z","iopub.execute_input":"2023-12-15T03:04:23.746070Z","iopub.status.idle":"2023-12-15T03:04:45.370833Z","shell.execute_reply.started":"2023-12-15T03:04:23.746040Z","shell.execute_reply":"2023-12-15T03:04:45.369928Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#Prediction based on test data \nmask_predictions = segmentation_model.predict(im_test_info)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T03:04:54.043735Z","iopub.execute_input":"2023-12-15T03:04:54.044595Z","iopub.status.idle":"2023-12-15T03:05:18.585805Z","shell.execute_reply.started":"2023-12-15T03:04:54.044560Z","shell.execute_reply":"2023-12-15T03:05:18.584883Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"12/12 [==============================] - 2s 115ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#Converting into 0,1\nmask_predictions = (mask_predictions > 0.5).astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T03:05:26.046647Z","iopub.execute_input":"2023-12-15T03:05:26.047535Z","iopub.status.idle":"2023-12-15T03:05:26.086510Z","shell.execute_reply.started":"2023-12-15T03:05:26.047500Z","shell.execute_reply":"2023-12-15T03:05:26.085419Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#Jaccard_Index\ndef jaccard_index(y_true_info, y_prediction_info, smooth=1.0):\n    intersection = np.sum(y_true_info * y_prediction_info)\n    union = np.sum(y_true_info) + np.sum(y_prediction_info) - intersection\n    iou = (intersection + smooth) / (union + smooth)\n    return iou","metadata":{"execution":{"iopub.status.busy":"2023-12-15T03:05:44.409914Z","iopub.execute_input":"2023-12-15T03:05:44.410289Z","iopub.status.idle":"2023-12-15T03:05:44.415847Z","shell.execute_reply.started":"2023-12-15T03:05:44.410263Z","shell.execute_reply":"2023-12-15T03:05:44.414908Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#calculation of Jaccard Index \niou_metric = jaccard_index(mask_test_info,mask_predictions)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T03:05:50.076671Z","iopub.execute_input":"2023-12-15T03:05:50.077516Z","iopub.status.idle":"2023-12-15T03:05:50.163134Z","shell.execute_reply.started":"2023-12-15T03:05:50.077483Z","shell.execute_reply":"2023-12-15T03:05:50.162340Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"iou_metric","metadata":{"execution":{"iopub.status.busy":"2023-12-15T03:05:53.850001Z","iopub.execute_input":"2023-12-15T03:05:53.850367Z","iopub.status.idle":"2023-12-15T03:05:53.856782Z","shell.execute_reply.started":"2023-12-15T03:05:53.850337Z","shell.execute_reply":"2023-12-15T03:05:53.855798Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"0.7628783917533198"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}